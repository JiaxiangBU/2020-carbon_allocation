{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"from math import sqrt\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\n\\nfrom tensorflow.keras.models import Sequential, load_model\\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM\\nfrom tensorflow.keras.optimizers import Adam\\n\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport os\\nimport pandas as pd\\nimport pickle\\n\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"from math import sqrt\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\n\\nfrom tensorflow.keras.models import Sequential, load_model\\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM\\nfrom tensorflow.keras.optimizers import Adam\\n\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport os\\nimport pandas as pd\\nimport pickle\\n\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>Fixed asset</th>\n",
       "      <th>Energy consumption</th>\n",
       "      <th>GDP</th>\n",
       "      <th>CO2 emisson</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City name</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Beijing</th>\n",
       "      <th>2000</th>\n",
       "      <th>Eastern</th>\n",
       "      <td>1364</td>\n",
       "      <td>6275.807717</td>\n",
       "      <td>4144.00</td>\n",
       "      <td>2478.76</td>\n",
       "      <td>63.471917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tianjin</th>\n",
       "      <th>2000</th>\n",
       "      <th>Eastern</th>\n",
       "      <td>1001</td>\n",
       "      <td>2868.107570</td>\n",
       "      <td>2794.00</td>\n",
       "      <td>1639.36</td>\n",
       "      <td>66.947012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hebei</th>\n",
       "      <th>2000</th>\n",
       "      <th>Eastern</th>\n",
       "      <td>6674</td>\n",
       "      <td>10259.492829</td>\n",
       "      <td>11195.71</td>\n",
       "      <td>5088.96</td>\n",
       "      <td>257.928655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shanxi</th>\n",
       "      <th>2000</th>\n",
       "      <th>Central</th>\n",
       "      <td>3247</td>\n",
       "      <td>1890.159429</td>\n",
       "      <td>6728.00</td>\n",
       "      <td>1643.81</td>\n",
       "      <td>87.943157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InnerMongolia</th>\n",
       "      <th>2000</th>\n",
       "      <th>Western</th>\n",
       "      <td>2372</td>\n",
       "      <td>930.063035</td>\n",
       "      <td>3937.54</td>\n",
       "      <td>1401.01</td>\n",
       "      <td>110.866970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Population   Fixed asset  Energy consumption  \\\n",
       "City name     year region                                                  \n",
       "Beijing       2000 Eastern        1364   6275.807717             4144.00   \n",
       "Tianjin       2000 Eastern        1001   2868.107570             2794.00   \n",
       "Hebei         2000 Eastern        6674  10259.492829            11195.71   \n",
       "Shanxi        2000 Central        3247   1890.159429             6728.00   \n",
       "InnerMongolia 2000 Western        2372    930.063035             3937.54   \n",
       "\n",
       "                                GDP  CO2 emisson  \n",
       "City name     year region                         \n",
       "Beijing       2000 Eastern  2478.76    63.471917  \n",
       "Tianjin       2000 Eastern  1639.36    66.947012  \n",
       "Hebei         2000 Eastern  5088.96   257.928655  \n",
       "Shanxi        2000 Central  1643.81    87.943157  \n",
       "InnerMongolia 2000 Western  1401.01   110.866970  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"data_path = r\\\"D:\\\\tencent files\\\\chrome Download\\\\Research\\\\DEA\\\\DEA_carbon market\\\\Data\\\\Data.xlsx\\\"  # set file path\\n\\ndata = pd.read_excel(data_path, sheet_name=\\\"DEA_data\\\").set_index(\\n    [\\\"City name\\\", \\\"year\\\", \\\"region\\\"]\\n)  # read file, set province name as index\\ndata.head()\";\n",
       "                var nbb_formatted_code = \"data_path = r\\\"D:\\\\tencent files\\\\chrome Download\\\\Research\\\\DEA\\\\DEA_carbon market\\\\Data\\\\Data.xlsx\\\"  # set file path\\n\\ndata = pd.read_excel(data_path, sheet_name=\\\"DEA_data\\\").set_index(\\n    [\\\"City name\\\", \\\"year\\\", \\\"region\\\"]\\n)  # read file, set province name as index\\ndata.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = r\"D:\\tencent files\\chrome Download\\Research\\DEA\\DEA_carbon market\\Data\\Data.xlsx\"  # set file path\n",
    "\n",
    "data = pd.read_excel(data_path, sheet_name=\"DEA_data\").set_index(\n",
    "    [\"City name\", \"year\", \"region\"]\n",
    ")  # read file, set province name as index\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>Fixed asset</th>\n",
       "      <th>Energy consumption</th>\n",
       "      <th>GDP</th>\n",
       "      <th>CO2 emisson</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City name</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Beijing</th>\n",
       "      <th>2000</th>\n",
       "      <th>Eastern</th>\n",
       "      <td>0.079516</td>\n",
       "      <td>0.024219</td>\n",
       "      <td>0.095810</td>\n",
       "      <td>0.040386</td>\n",
       "      <td>0.040393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tianjin</th>\n",
       "      <th>2000</th>\n",
       "      <th>Eastern</th>\n",
       "      <td>0.045437</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.060509</td>\n",
       "      <td>0.025082</td>\n",
       "      <td>0.042633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hebei</th>\n",
       "      <th>2000</th>\n",
       "      <th>Eastern</th>\n",
       "      <td>0.578014</td>\n",
       "      <td>0.041323</td>\n",
       "      <td>0.280203</td>\n",
       "      <td>0.087974</td>\n",
       "      <td>0.165753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shanxi</th>\n",
       "      <th>2000</th>\n",
       "      <th>Central</th>\n",
       "      <td>0.256290</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.163378</td>\n",
       "      <td>0.025164</td>\n",
       "      <td>0.056169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InnerMongolia</th>\n",
       "      <th>2000</th>\n",
       "      <th>Western</th>\n",
       "      <td>0.174146</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.090411</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>0.070947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Population  Fixed asset  Energy consumption  \\\n",
       "City name     year region                                                 \n",
       "Beijing       2000 Eastern    0.079516     0.024219            0.095810   \n",
       "Tianjin       2000 Eastern    0.045437     0.009587            0.060509   \n",
       "Hebei         2000 Eastern    0.578014     0.041323            0.280203   \n",
       "Shanxi        2000 Central    0.256290     0.005388            0.163378   \n",
       "InnerMongolia 2000 Western    0.174146     0.001266            0.090411   \n",
       "\n",
       "                                 GDP  CO2 emisson  \n",
       "City name     year region                          \n",
       "Beijing       2000 Eastern  0.040386     0.040393  \n",
       "Tianjin       2000 Eastern  0.025082     0.042633  \n",
       "Hebei         2000 Eastern  0.087974     0.165753  \n",
       "Shanxi        2000 Central  0.025164     0.056169  \n",
       "InnerMongolia 2000 Western  0.020737     0.070947  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"scaler = MinMaxScaler(feature_range=(0, 1))  # setup scaler\\n\\nscaled = scaler.fit_transform(data)  # transform data into n*5 scaled arrays\\nscaled_df = pd.DataFrame(\\n    scaled, index=data.index, columns=data.columns\\n)  # set scaled arrays as dataframe\\nscaled_df.head()\";\n",
       "                var nbb_formatted_code = \"scaler = MinMaxScaler(feature_range=(0, 1))  # setup scaler\\n\\nscaled = scaler.fit_transform(data)  # transform data into n*5 scaled arrays\\nscaled_df = pd.DataFrame(\\n    scaled, index=data.index, columns=data.columns\\n)  # set scaled arrays as dataframe\\nscaled_df.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))  # setup scaler\n",
    "\n",
    "scaled = scaler.fit_transform(data)  # transform data into n*5 scaled arrays\n",
    "scaled_df = pd.DataFrame(\n",
    "    scaled, index=data.index, columns=data.columns\n",
    ")  # set scaled arrays as dataframe\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"Input_lag = 16\";\n",
       "                var nbb_formatted_code = \"Input_lag = 16\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Input_lag = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"def series_to_supervised(df, n_in=Input_lag, n_out=1, dropnan=True):\\n\\n    n_vars = 1 if type(df) is list else df.shape[1]\\n    # if number of variables is 1 when input data type is a list, else the number is the shape of data\\n\\n    cols, names = list(), list()\\n    # input sequence (t-n, ... t-1)\\n    for i in range(n_in, 0, -1):\\n        cols.append(df.shift(i))  # shift dataframe values forward for i period\\n        names += [(\\\"var%d(t-%d)\\\" % (j + 1, i)) for j in range(n_vars)]\\n    # forecast sequence (t, t+1, ... t+n)\\n    for i in range(0, n_out):\\n        cols.append(df.shift(-i))\\n        if i == 0:\\n            names += [(\\\"var%d(t)\\\" % (j + 1)) for j in range(n_vars)]\\n        else:\\n            names += [(\\\"var%d(t+%d)\\\" % (j + 1, i)) for j in range(n_vars)]\\n    # put it all together\\n    agg = pd.concat(cols, axis=1)\\n    agg.columns = names\\n    # drop rows with NaN values\\n    if dropnan:\\n        agg.dropna(inplace=True)\\n    return agg\";\n",
       "                var nbb_formatted_code = \"def series_to_supervised(df, n_in=Input_lag, n_out=1, dropnan=True):\\n\\n    n_vars = 1 if type(df) is list else df.shape[1]\\n    # if number of variables is 1 when input data type is a list, else the number is the shape of data\\n\\n    cols, names = list(), list()\\n    # input sequence (t-n, ... t-1)\\n    for i in range(n_in, 0, -1):\\n        cols.append(df.shift(i))  # shift dataframe values forward for i period\\n        names += [(\\\"var%d(t-%d)\\\" % (j + 1, i)) for j in range(n_vars)]\\n    # forecast sequence (t, t+1, ... t+n)\\n    for i in range(0, n_out):\\n        cols.append(df.shift(-i))\\n        if i == 0:\\n            names += [(\\\"var%d(t)\\\" % (j + 1)) for j in range(n_vars)]\\n        else:\\n            names += [(\\\"var%d(t+%d)\\\" % (j + 1, i)) for j in range(n_vars)]\\n    # put it all together\\n    agg = pd.concat(cols, axis=1)\\n    agg.columns = names\\n    # drop rows with NaN values\\n    if dropnan:\\n        agg.dropna(inplace=True)\\n    return agg\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def series_to_supervised(df, n_in=Input_lag, n_out=1, dropnan=True):\n",
    "\n",
    "    n_vars = 1 if type(df) is list else df.shape[1]\n",
    "    # if number of variables is 1 when input data type is a list, else the number is the shape of data\n",
    "\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))  # shift dataframe values forward for i period\n",
    "        names += [(\"var%d(t-%d)\" % (j + 1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [(\"var%d(t)\" % (j + 1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [(\"var%d(t+%d)\" % (j + 1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"def train_test_split(data, n_var=Input_lag * 5):\\n    \\\"\\\"\\\"\\n    split train and test groups by 80% and 20%\\n    \\\"\\\"\\\"\\n    size = int(len(data) * 0.8)\\n    # for train data will be collected from each country's data which index is from 0-size (80%)\\n    x_train = data.iloc[0:size, 0:n_var]\\n    # for test data will be collected from each country's  data which index is from size to the end (20%)\\n    x_test = data.iloc[size:, 0:n_var]\\n    y_train = data.iloc[0:size, n_var:]\\n    y_test = data.iloc[size:, n_var:]\\n    return x_train, x_test, y_train, y_test\";\n",
       "                var nbb_formatted_code = \"def train_test_split(data, n_var=Input_lag * 5):\\n    \\\"\\\"\\\"\\n    split train and test groups by 80% and 20%\\n    \\\"\\\"\\\"\\n    size = int(len(data) * 0.8)\\n    # for train data will be collected from each country's data which index is from 0-size (80%)\\n    x_train = data.iloc[0:size, 0:n_var]\\n    # for test data will be collected from each country's  data which index is from size to the end (20%)\\n    x_test = data.iloc[size:, 0:n_var]\\n    y_train = data.iloc[0:size, n_var:]\\n    y_test = data.iloc[size:, n_var:]\\n    return x_train, x_test, y_train, y_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_test_split(data, n_var=Input_lag * 5):\n",
    "    \"\"\"\n",
    "    split train and test groups by 80% and 20%\n",
    "    \"\"\"\n",
    "    size = int(len(data) * 0.8)\n",
    "    # for train data will be collected from each country's data which index is from 0-size (80%)\n",
    "    x_train = data.iloc[0:size, 0:n_var]\n",
    "    # for test data will be collected from each country's  data which index is from size to the end (20%)\n",
    "    x_test = data.iloc[size:, 0:n_var]\n",
    "    y_train = data.iloc[0:size, n_var:]\n",
    "    y_test = data.iloc[size:, n_var:]\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"def reshape(dataframe):\\n    \\\"\\\"\\\"\\n    Reshape dataframe into np.array fitting to LSTM\\n    \\\"\\\"\\\"\\n    array = dataframe.values.reshape(dataframe.shape[0], 1, dataframe.shape[1])\\n    return array\";\n",
       "                var nbb_formatted_code = \"def reshape(dataframe):\\n    \\\"\\\"\\\"\\n    Reshape dataframe into np.array fitting to LSTM\\n    \\\"\\\"\\\"\\n    array = dataframe.values.reshape(dataframe.shape[0], 1, dataframe.shape[1])\\n    return array\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def reshape(dataframe):\n",
    "    \"\"\"\n",
    "    Reshape dataframe into np.array fitting to LSTM\n",
    "    \"\"\"\n",
    "    array = dataframe.values.reshape(dataframe.shape[0], 1, dataframe.shape[1])\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"def data_process(province, scaled_df=scaled_df):\\n    data = scaled_df[\\n        scaled_df.index.get_level_values(\\\"City name\\\") == province\\n    ]  # data transferred to (n_varX+n_varY)*(12-n_varX/5)\\n    data = series_to_supervised(\\n        data[data.index.get_level_values(\\\"City name\\\") == province]\\n    )\\n    x_train, x_test, y_train, y_test = train_test_split(data)\\n    x_train_array, x_test_array, y_train_array, y_test_array = (\\n        reshape(x_train),\\n        reshape(x_test),\\n        reshape(y_train),\\n        reshape(y_test),\\n    )\\n    return x_train_array, x_test_array, y_train_array, y_test_array\";\n",
       "                var nbb_formatted_code = \"def data_process(province, scaled_df=scaled_df):\\n    data = scaled_df[\\n        scaled_df.index.get_level_values(\\\"City name\\\") == province\\n    ]  # data transferred to (n_varX+n_varY)*(12-n_varX/5)\\n    data = series_to_supervised(\\n        data[data.index.get_level_values(\\\"City name\\\") == province]\\n    )\\n    x_train, x_test, y_train, y_test = train_test_split(data)\\n    x_train_array, x_test_array, y_train_array, y_test_array = (\\n        reshape(x_train),\\n        reshape(x_test),\\n        reshape(y_train),\\n        reshape(y_test),\\n    )\\n    return x_train_array, x_test_array, y_train_array, y_test_array\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def data_process(province, scaled_df=scaled_df):\n",
    "    data = scaled_df[\n",
    "        scaled_df.index.get_level_values(\"City name\") == province\n",
    "    ]  # data transferred to (n_varX+n_varY)*(12-n_varX/5)\n",
    "    data = series_to_supervised(\n",
    "        data[data.index.get_level_values(\"City name\") == province]\n",
    "    )\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data)\n",
    "    x_train_array, x_test_array, y_train_array, y_test_array = (\n",
    "        reshape(x_train),\n",
    "        reshape(x_test),\n",
    "        reshape(y_train),\n",
    "        reshape(y_test),\n",
    "    )\n",
    "    return x_train_array, x_test_array, y_train_array, y_test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"province_list = list(\\n    dict.fromkeys([i[0] for i in scaled_df.index])\\n)  # get the list of province names, drop duplicate names while keep order\\n\\nX_train = []\\nX_test = []\\nY_train = []\\nY_test = []\\n\\nfor province in province_list:\\n    x_train_array, x_test_array, y_train_array, y_test_array = data_process(province)\\n\\n    X_train.append(x_train_array)\\n    X_test.append(x_test_array)\\n    Y_train.append(y_train_array)\\n    Y_test.append(y_test_array)  # get train & test sets\";\n",
       "                var nbb_formatted_code = \"province_list = list(\\n    dict.fromkeys([i[0] for i in scaled_df.index])\\n)  # get the list of province names, drop duplicate names while keep order\\n\\nX_train = []\\nX_test = []\\nY_train = []\\nY_test = []\\n\\nfor province in province_list:\\n    x_train_array, x_test_array, y_train_array, y_test_array = data_process(province)\\n\\n    X_train.append(x_train_array)\\n    X_test.append(x_test_array)\\n    Y_train.append(y_train_array)\\n    Y_test.append(y_test_array)  # get train & test sets\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "province_list = list(\n",
    "    dict.fromkeys([i[0] for i in scaled_df.index])\n",
    ")  # get the list of province names, drop duplicate names while keep order\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "\n",
    "for province in province_list:\n",
    "    x_train_array, x_test_array, y_train_array, y_test_array = data_process(province)\n",
    "\n",
    "    X_train.append(x_train_array)\n",
    "    X_test.append(x_test_array)\n",
    "    Y_train.append(y_train_array)\n",
    "    Y_test.append(y_test_array)  # get train & test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"def mean_absolute_percentage_error(y_true, y_pred):\\n\\n    ## Note: does not handle mix 1d representation\\n    # if _is_1d(y_true):\\n    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\\n\\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\";\n",
       "                var nbb_formatted_code = \"def mean_absolute_percentage_error(y_true, y_pred):\\n\\n    ## Note: does not handle mix 1d representation\\n    # if _is_1d(y_true):\\n    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\\n\\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "\n",
    "    ## Note: does not handle mix 1d representation\n",
    "    # if _is_1d(y_true):\n",
    "    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\n",
    "\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"def model_train(\\n    i,\\n    neurons_First,\\n    neurons_Second,\\n    layer=1,\\n    dropout=0.2,\\n    learning_rate=0.01,\\n    epochs=200,\\n    loss=\\\"mae\\\",\\n):\\n    \\\"\\\"\\\"\\n    Train LSTM model for different provinces to predict their population, GDP, capital stock, CO2, enery consumption\\n    \\\"\\\"\\\"\\n    # design network for confirmed cases data\\n    model = Sequential()\\n    model.add(\\n        LSTM(\\n            neurons_First,\\n            activation=\\\"relu\\\",\\n            input_shape=(\\n                X_train[i].shape[1],\\n                X_train[i].shape[2],\\n            ),\\n            return_sequences=(\\n                True if layer == 2 else False\\n            ),  # LSTM layer requires 3D input, by using 'return_sequeces' argument,\\n            # the layer returns LSTM output as same as input\\n            dropout=dropout,\\n        )\\n    )  # add LSTM layer\\n\\n    if layer == 2:\\n        model.add(Dropout(dropout))\\n\\n        model.add(LSTM(neurons_Second, activation=\\\"relu\\\"))  # stacked LSTM model\\n        model.add(Dropout(dropout))\\n\\n    model.add(Dense(5))  # add output layer\\n\\n    optimizer = Adam(lr=learning_rate, decay=1e-6)\\n    model.compile(loss=loss, optimizer=optimizer)  # add loss function and optimizer\\n\\n    # fit network\\n    model_train = model.fit(\\n        X_train[i],\\n        Y_train[i],\\n        epochs=epochs,\\n        validation_data=(X_test[i], Y_test[i]),\\n        verbose=0,\\n        shuffle=False,\\n    )\\n\\n    # make a prediction\\n    yhat = model.predict(X_test[i])\\n\\n    # invert scaling for forecast\\n    inv_yhat = scaler.inverse_transform(yhat)\\n    inv_y = scaler.inverse_transform(\\n        Y_test[i].reshape(Y_test[i].shape[0], Y_test[i].shape[2])\\n    )\\n    # calculate RMSE\\n    rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\\n    mape = mean_absolute_percentage_error(inv_y, inv_yhat)\\n\\n    # save model\\n    path = r\\\"E:\\\\desktop\\\\PythonScipt\\\\keras_models\\\\ZSG_DEA\\\"\\n    os.chdir(path)\\n    if (province_list[i] + \\\"_lstm.h5\\\") not in os.listdir(path):\\n        model.save(province_list[i] + \\\"_lstm.h5\\\")\\n\\n    return rmse, mape, yhat\";\n",
       "                var nbb_formatted_code = \"def model_train(\\n    i,\\n    neurons_First,\\n    neurons_Second,\\n    layer=1,\\n    dropout=0.2,\\n    learning_rate=0.01,\\n    epochs=200,\\n    loss=\\\"mae\\\",\\n):\\n    \\\"\\\"\\\"\\n    Train LSTM model for different provinces to predict their population, GDP, capital stock, CO2, enery consumption\\n    \\\"\\\"\\\"\\n    # design network for confirmed cases data\\n    model = Sequential()\\n    model.add(\\n        LSTM(\\n            neurons_First,\\n            activation=\\\"relu\\\",\\n            input_shape=(\\n                X_train[i].shape[1],\\n                X_train[i].shape[2],\\n            ),\\n            return_sequences=(\\n                True if layer == 2 else False\\n            ),  # LSTM layer requires 3D input, by using 'return_sequeces' argument,\\n            # the layer returns LSTM output as same as input\\n            dropout=dropout,\\n        )\\n    )  # add LSTM layer\\n\\n    if layer == 2:\\n        model.add(Dropout(dropout))\\n\\n        model.add(LSTM(neurons_Second, activation=\\\"relu\\\"))  # stacked LSTM model\\n        model.add(Dropout(dropout))\\n\\n    model.add(Dense(5))  # add output layer\\n\\n    optimizer = Adam(lr=learning_rate, decay=1e-6)\\n    model.compile(loss=loss, optimizer=optimizer)  # add loss function and optimizer\\n\\n    # fit network\\n    model_train = model.fit(\\n        X_train[i],\\n        Y_train[i],\\n        epochs=epochs,\\n        validation_data=(X_test[i], Y_test[i]),\\n        verbose=0,\\n        shuffle=False,\\n    )\\n\\n    # make a prediction\\n    yhat = model.predict(X_test[i])\\n\\n    # invert scaling for forecast\\n    inv_yhat = scaler.inverse_transform(yhat)\\n    inv_y = scaler.inverse_transform(\\n        Y_test[i].reshape(Y_test[i].shape[0], Y_test[i].shape[2])\\n    )\\n    # calculate RMSE\\n    rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\\n    mape = mean_absolute_percentage_error(inv_y, inv_yhat)\\n\\n    # save model\\n    path = r\\\"E:\\\\desktop\\\\PythonScipt\\\\keras_models\\\\ZSG_DEA\\\"\\n    os.chdir(path)\\n    if (province_list[i] + \\\"_lstm.h5\\\") not in os.listdir(path):\\n        model.save(province_list[i] + \\\"_lstm.h5\\\")\\n\\n    return rmse, mape, yhat\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def model_train(\n",
    "    i,\n",
    "    neurons_First,\n",
    "    neurons_Second,\n",
    "    layer=1,\n",
    "    dropout=0.2,\n",
    "    learning_rate=0.01,\n",
    "    epochs=200,\n",
    "    loss=\"mae\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Train LSTM model for different provinces to predict their population, GDP, capital stock, CO2, enery consumption\n",
    "    \"\"\"\n",
    "    # design network for confirmed cases data\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        LSTM(\n",
    "            neurons_First,\n",
    "            activation=\"relu\",\n",
    "            input_shape=(\n",
    "                X_train[i].shape[1],\n",
    "                X_train[i].shape[2],\n",
    "            ),\n",
    "            return_sequences=(\n",
    "                True if layer == 2 else False\n",
    "            ),  # LSTM layer requires 3D input, by using 'return_sequeces' argument,\n",
    "            # the layer returns LSTM output as same as input\n",
    "            dropout=dropout,\n",
    "        )\n",
    "    )  # add LSTM layer\n",
    "\n",
    "    if layer == 2:\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(LSTM(neurons_Second, activation=\"relu\"))  # stacked LSTM model\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(5))  # add output layer\n",
    "\n",
    "    optimizer = Adam(lr=learning_rate, decay=1e-6)\n",
    "    model.compile(loss=loss, optimizer=optimizer)  # add loss function and optimizer\n",
    "\n",
    "    # fit network\n",
    "    model_train = model.fit(\n",
    "        X_train[i],\n",
    "        Y_train[i],\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_test[i], Y_test[i]),\n",
    "        verbose=0,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    # make a prediction\n",
    "    yhat = model.predict(X_test[i])\n",
    "\n",
    "    # invert scaling for forecast\n",
    "    inv_yhat = scaler.inverse_transform(yhat)\n",
    "    inv_y = scaler.inverse_transform(\n",
    "        Y_test[i].reshape(Y_test[i].shape[0], Y_test[i].shape[2])\n",
    "    )\n",
    "    # calculate RMSE\n",
    "    rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "    mape = mean_absolute_percentage_error(inv_y, inv_yhat)\n",
    "\n",
    "    # save model\n",
    "    path = r\"E:\\desktop\\PythonScipt\\keras_models\\ZSG_DEA\"\n",
    "    os.chdir(path)\n",
    "    if (province_list[i] + \"_lstm.h5\") not in os.listdir(path):\n",
    "        model.save(province_list[i] + \"_lstm.h5\")\n",
    "\n",
    "    return rmse, mape, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"length = len(province_list)\\ndropout = 0\\nneurons_First = 40\\nneurons_Second = 20\\nlayer = 1\\nlr = 0.01\\nepochs = 400\\nloss = \\\"mae\\\"\";\n",
       "                var nbb_formatted_code = \"length = len(province_list)\\ndropout = 0\\nneurons_First = 40\\nneurons_Second = 20\\nlayer = 1\\nlr = 0.01\\nepochs = 400\\nloss = \\\"mae\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length = len(province_list)\n",
    "dropout = 0\n",
    "neurons_First = 40\n",
    "neurons_Second = 20\n",
    "layer = 1\n",
    "lr = 0.01\n",
    "epochs = 400\n",
    "loss = \"mae\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_list, rmse_list = [], []\n",
    "\n",
    "for province_i in range(length):\n",
    "    rmse, mape, yhat = model_train(\n",
    "        province_i,\n",
    "        neurons_First,\n",
    "        neurons_Second,\n",
    "        layer,\n",
    "        dropout=dropout,\n",
    "        learning_rate=lr,\n",
    "        epochs=epochs,\n",
    "        loss=loss,\n",
    "    )\n",
    "    mape_list.append(mape)\n",
    "    rmse_list.append(rmse)\n",
    "    print(\"{}: rmse {:.3f} \\nmape {:.3f}\".format(province_list[province_i], rmse, mape))\n",
    "\n",
    "sum(mape_list) / length, sum(rmse_list) / length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"model_file_list = os.listdir(r\\\"E:\\\\desktop\\\\PythonScipt\\\\keras_models\\\\ZSG_DEA\\\")\";\n",
       "                var nbb_formatted_code = \"model_file_list = os.listdir(r\\\"E:\\\\desktop\\\\PythonScipt\\\\keras_models\\\\ZSG_DEA\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_file_list = os.listdir(r\"E:\\desktop\\PythonScipt\\keras_models\\ZSG_DEA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"def model_load(i):\\n    model_file = [\\n        file_name for file_name in model_file_list if province_list[i] in file_name\\n    ][0]\\n    model = load_model(model_file)\\n    yhat = model.predict(X_test[i])\\n    return model, yhat\";\n",
       "                var nbb_formatted_code = \"def model_load(i):\\n    model_file = [\\n        file_name for file_name in model_file_list if province_list[i] in file_name\\n    ][0]\\n    model = load_model(model_file)\\n    yhat = model.predict(X_test[i])\\n    return model, yhat\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def model_load(i):\n",
    "    model_file = [\n",
    "        file_name for file_name in model_file_list if province_list[i] in file_name\n",
    "    ][0]\n",
    "    model = load_model(model_file)\n",
    "    yhat = model.predict(X_test[i])\n",
    "    return model, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"def model_prediction(i, model, y_predict, scaled_df=scaled_df):\\n\\n    # predict next timestep based on previous times steps\\n    raw_data = scaled_df[\\n        scaled_df.index.get_level_values(\\\"City name\\\") == province_list[i]\\n    ]\\n\\n    tuples = [(province_list[i], raw_data.index[-1][1] + 1, raw_data.index[-1][2])]\\n    index = pd.MultiIndex.from_tuples(tuples)\\n\\n    y_predict_df = pd.DataFrame(\\n        y_predict, columns=raw_data.columns, index=index\\n    )  # transfer ndarray into dataframe\\n\\n    data_update_df = pd.concat(\\n        [raw_data, y_predict_df]\\n    )  # concatnate original data with predicted data\\n\\n    data_update = series_to_supervised(data_update_df)\\n    x_train, x_test, y_train, y_test = train_test_split(data_update)\\n    x_train_array, x_test_array, y_train_array, y_test_array = (\\n        reshape(x_train),\\n        reshape(x_test),\\n        reshape(y_train),\\n        reshape(y_test),\\n    )\\n\\n    y_predict = model.predict(x_test_array)\\n\\n    return y_predict, data_update_df\";\n",
       "                var nbb_formatted_code = \"def model_prediction(i, model, y_predict, scaled_df=scaled_df):\\n\\n    # predict next timestep based on previous times steps\\n    raw_data = scaled_df[\\n        scaled_df.index.get_level_values(\\\"City name\\\") == province_list[i]\\n    ]\\n\\n    tuples = [(province_list[i], raw_data.index[-1][1] + 1, raw_data.index[-1][2])]\\n    index = pd.MultiIndex.from_tuples(tuples)\\n\\n    y_predict_df = pd.DataFrame(\\n        y_predict, columns=raw_data.columns, index=index\\n    )  # transfer ndarray into dataframe\\n\\n    data_update_df = pd.concat(\\n        [raw_data, y_predict_df]\\n    )  # concatnate original data with predicted data\\n\\n    data_update = series_to_supervised(data_update_df)\\n    x_train, x_test, y_train, y_test = train_test_split(data_update)\\n    x_train_array, x_test_array, y_train_array, y_test_array = (\\n        reshape(x_train),\\n        reshape(x_test),\\n        reshape(y_train),\\n        reshape(y_test),\\n    )\\n\\n    y_predict = model.predict(x_test_array)\\n\\n    return y_predict, data_update_df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def model_prediction(i, model, y_predict, scaled_df=scaled_df):\n",
    "\n",
    "    # predict next timestep based on previous times steps\n",
    "    raw_data = scaled_df[\n",
    "        scaled_df.index.get_level_values(\"City name\") == province_list[i]\n",
    "    ]\n",
    "\n",
    "    tuples = [(province_list[i], raw_data.index[-1][1] + 1, raw_data.index[-1][2])]\n",
    "    index = pd.MultiIndex.from_tuples(tuples)\n",
    "\n",
    "    y_predict_df = pd.DataFrame(\n",
    "        y_predict, columns=raw_data.columns, index=index\n",
    "    )  # transfer ndarray into dataframe\n",
    "\n",
    "    data_update_df = pd.concat(\n",
    "        [raw_data, y_predict_df]\n",
    "    )  # concatnate original data with predicted data\n",
    "\n",
    "    data_update = series_to_supervised(data_update_df)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_update)\n",
    "    x_train_array, x_test_array, y_train_array, y_test_array = (\n",
    "        reshape(x_train),\n",
    "        reshape(x_test),\n",
    "        reshape(y_train),\n",
    "        reshape(y_test),\n",
    "    )\n",
    "\n",
    "    y_predict = model.predict(x_test_array)\n",
    "\n",
    "    return y_predict, data_update_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"def future_prediction(i, future_period):\\n\\n    y_list = []\\n    for period in range(future_period):\\n        if period == 0:\\n            model, yhat = model_load(i)\\n            y_predict, data_update_df = model_prediction(i, model, yhat)\\n            row, col = y_predict.shape[0], y_predict.shape[1]\\n            y_list.append(y_predict)\\n        else:\\n            y_predict, data_update_df = model_prediction(\\n                i, model, y_predict, data_update_df\\n            )\\n            y_predict = np.reshape(y_predict[-1], (row, col))\\n            y_list.append(y_predict)\\n\\n    return data_update_df\";\n",
       "                var nbb_formatted_code = \"def future_prediction(i, future_period):\\n\\n    y_list = []\\n    for period in range(future_period):\\n        if period == 0:\\n            model, yhat = model_load(i)\\n            y_predict, data_update_df = model_prediction(i, model, yhat)\\n            row, col = y_predict.shape[0], y_predict.shape[1]\\n            y_list.append(y_predict)\\n        else:\\n            y_predict, data_update_df = model_prediction(\\n                i, model, y_predict, data_update_df\\n            )\\n            y_predict = np.reshape(y_predict[-1], (row, col))\\n            y_list.append(y_predict)\\n\\n    return data_update_df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def future_prediction(i, future_period):\n",
    "\n",
    "    y_list = []\n",
    "    for period in range(future_period):\n",
    "        if period == 0:\n",
    "            model, yhat = model_load(i)\n",
    "            y_predict, data_update_df = model_prediction(i, model, yhat)\n",
    "            row, col = y_predict.shape[0], y_predict.shape[1]\n",
    "            y_list.append(y_predict)\n",
    "        else:\n",
    "            y_predict, data_update_df = model_prediction(\n",
    "                i, model, y_predict, data_update_df\n",
    "            )\n",
    "            y_predict = np.reshape(y_predict[-1], (row, col))\n",
    "            y_list.append(y_predict)\n",
    "\n",
    "    return data_update_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"def inverse_df(i, future_period):\\n    data_update_df = future_prediction(i, future_period)\\n    data_final = scaler.inverse_transform(data_update_df)\\n    data_final_df = pd.DataFrame(\\n        data_final,\\n        columns=data_update_df.columns,\\n        index=range(2000, 2000 + data_final.shape[0]),\\n    )\\n    return data_final_df\";\n",
       "                var nbb_formatted_code = \"def inverse_df(i, future_period):\\n    data_update_df = future_prediction(i, future_period)\\n    data_final = scaler.inverse_transform(data_update_df)\\n    data_final_df = pd.DataFrame(\\n        data_final,\\n        columns=data_update_df.columns,\\n        index=range(2000, 2000 + data_final.shape[0]),\\n    )\\n    return data_final_df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def inverse_df(i, future_period):\n",
    "    data_update_df = future_prediction(i, future_period)\n",
    "    data_final = scaler.inverse_transform(data_update_df)\n",
    "    data_final_df = pd.DataFrame(\n",
    "        data_final,\n",
    "        columns=data_update_df.columns,\n",
    "        index=range(2000, 2000 + data_final.shape[0]),\n",
    "    )\n",
    "    return data_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"data_dict = {}\\nfor i in range(len(province_list)):\\n    data_dict[province_list[i]] = inverse_df(i, 13)\\n\\ndata_concat = pd.concat(data_dict)\";\n",
       "                var nbb_formatted_code = \"data_dict = {}\\nfor i in range(len(province_list)):\\n    data_dict[province_list[i]] = inverse_df(i, 13)\\n\\ndata_concat = pd.concat(data_dict)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dict = {}\n",
    "for i in range(len(province_list)):\n",
    "    data_dict[province_list[i]] = inverse_df(i, 13)\n",
    "\n",
    "data_concat = pd.concat(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"path = r\\\"D:\\\\tencent files\\\\chrome Download\\\\Research\\\\DEA\\\\DEA_carbon market\\\\Data\\\"\\nwith open(os.path.join(path, \\\"Data_lstm.pickle\\\"), \\\"wb\\\") as data:\\n    pickle.dump(data_concat, data)\";\n",
       "                var nbb_formatted_code = \"path = r\\\"D:\\\\tencent files\\\\chrome Download\\\\Research\\\\DEA\\\\DEA_carbon market\\\\Data\\\"\\nwith open(os.path.join(path, \\\"Data_lstm.pickle\\\"), \\\"wb\\\") as data:\\n    pickle.dump(data_concat, data)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = r\"D:\\tencent files\\chrome Download\\Research\\DEA\\DEA_carbon market\\Data\"\n",
    "with open(os.path.join(path, \"Data_lstm.pickle\"), \"wb\") as data:\n",
    "    pickle.dump(data_concat, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"data_concat.to_excel(\\n    r\\\"D:\\\\tencent files\\\\chrome Download\\\\Research\\\\DEA\\\\DEA_carbon market\\\\Data\\\\Data_lstm.xlsx\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"data_concat.to_excel(\\n    r\\\"D:\\\\tencent files\\\\chrome Download\\\\Research\\\\DEA\\\\DEA_carbon market\\\\Data\\\\Data_lstm.xlsx\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_concat.to_excel(\n",
    "    r\"D:\\tencent files\\chrome Download\\Research\\DEA\\DEA_carbon market\\Data\\Data_lstm.xlsx\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
